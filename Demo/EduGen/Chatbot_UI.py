import streamlit as st
import requests
import time

# FastAPI ì„œë²„ ì£¼ì†Œ
FASTAPI_URL = "http://127.0.0.1:8000/generate"

# --- Streamlit UI ì„¤ì • ---
st.set_page_config(page_title="Study Agent Chatbot", page_icon="ğŸ¤–")
st.title("ğŸ¤– Study Agent Chatbot")
st.caption("LangGraph RAG Agentì™€ ëŒ€í™”í•˜ì—¬ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ìƒì„±í•´ë³´ì„¸ìš”.")

# ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì£¼ì œì— ëŒ€í•œ í•™ìŠµ ì½˜í…ì¸ ë¥¼ ë§Œë“¤ì–´ ë“œë¦´ê¹Œìš”?"}
    ]

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì˜ˆ: ê³ ë“±í•™êµ 1í•™ë…„ ìˆ˜í•™ 'ì§‘í•©'"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì™€ í™”ë©´ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ìœ„í•œ ì¤€ë¹„
    with st.chat_message("assistant"):
        # ë¡œë”© ìŠ¤í”¼ë„ˆ í‘œì‹œ
        with st.spinner("ì—ì´ì „íŠ¸ê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
            try:
                # FastAPI ì„œë²„ë¡œ ìš”ì²­ ì „ì†¡ (5ë¶„ íƒ€ì„ì•„ì›ƒ)
                response = requests.post(FASTAPI_URL, json={"prompt": prompt}, timeout=90)
                response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬

                data = response.json()
                full_response = data.get("response", "ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            except requests.exceptions.RequestException as e:
                full_response = f"ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {e}\n\nFastAPI ì„œë²„(`app.py`)ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                st.error(full_response)
            except Exception as e:
                full_response = f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                st.error(full_response)

        # íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ì£¼ë©° ì‘ë‹µ í‘œì‹œ
        response_container = st.empty()
        typed_response = ""
        for chunk in full_response.split():
            typed_response += chunk + " "
            time.sleep(0.05)
            response_container.markdown(typed_response + "â–Œ")
        response_container.markdown(typed_response)

    # ìµœì¢… ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})